{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T23:56:46.273611Z",
     "iopub.status.busy": "2025-12-21T23:56:46.273448Z",
     "iopub.status.idle": "2025-12-21T23:56:54.809189Z",
     "shell.execute_reply": "2025-12-21T23:56:54.808729Z",
     "shell.execute_reply.started": "2025-12-21T23:56:46.273595Z"
    },
    "id": "8ZnGKp70iw0T",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import editdistance\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T23:56:54.810011Z",
     "iopub.status.busy": "2025-12-21T23:56:54.809742Z",
     "iopub.status.idle": "2025-12-21T23:56:54.814655Z",
     "shell.execute_reply": "2025-12-21T23:56:54.814187Z",
     "shell.execute_reply.started": "2025-12-21T23:56:54.809997Z"
    },
    "id": "U9TFbfgtixvA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CRNN Model with ResNet18 Pretrained for OCR (https://postimg.cc/kDsRSZbg)\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size=512, pretrained=True):\n",
    "        super(CRNN, self).__init__()\n",
    "        # Khởi tạo EfficientNet-B5 làm backbone\n",
    "        # Tải trọng số ImageNet đã huấn luyện trước nếu pretrained=True\n",
    "        efficientnet = models.efficientnet_b5(weights=models.EfficientNet_B5_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        self.cnn = efficientnet.features\n",
    "\n",
    "        # feature_dim cho EfficientNet-B5 là 2048 kênh\n",
    "        self.feature_dim = 2048\n",
    "\n",
    "        # Lớp AdaptiveAvgPool2d để thay đổi kích thước đầu ra CNN thành chiều cao 1\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, None))\n",
    "\n",
    "        # Lớp LSTM để xử lý chuỗi đặc trưng\n",
    "        self.rnn = nn.LSTM(\n",
    "            self.feature_dim,      # Kích thước đầu vào (số kênh đặc trưng)\n",
    "            hidden_size,           # Kích thước trạng thái ẩn\n",
    "            bidirectional=True,    # Xử lý chuỗi theo cả hai hướng\n",
    "            num_layers=2,          # Số lớp LSTM\n",
    "            batch_first=True,      # Định dạng đầu vào/đầu ra là (batch, sequence, feature)\n",
    "            dropout=0.3\n",
    "        )\n",
    "        # Lớp tuyến tính cuối cùng để dự đoán các lớp (ký tự)\n",
    "        # hidden_size * 2 vì RNN là song hướng\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        conv = self.cnn(x)  # (batch, 512, H, W)\n",
    "\n",
    "        # Adaptive pooling to height=1\n",
    "        conv = self.adaptive_pool(conv)  # (batch, 512, 1, W)\n",
    "\n",
    "        # Remove height dimension\n",
    "        b, c, h, w = conv.size()\n",
    "        conv = conv.squeeze(2)  # (batch, 512, W)\n",
    "\n",
    "        # Permute for RNN: (batch, W, 512)\n",
    "        conv = conv.permute(0, 2, 1)\n",
    "\n",
    "        # RNN\n",
    "        output, _ = self.rnn(conv)\n",
    "\n",
    "        # FC\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T23:56:54.815331Z",
     "iopub.status.busy": "2025-12-21T23:56:54.815145Z",
     "iopub.status.idle": "2025-12-21T23:56:54.836709Z",
     "shell.execute_reply": "2025-12-21T23:56:54.836318Z",
     "shell.execute_reply.started": "2025-12-21T23:56:54.815320Z"
    },
    "id": "wh6gFwYYizxn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Character Encoder/Decoder\n",
    "class CharacterEncoder:\n",
    "    def __init__(self, labels_dict):\n",
    "        # Get all unique characters from labels\n",
    "        all_chars = set()\n",
    "        for text in labels_dict.values():\n",
    "            all_chars.update(text)\n",
    "\n",
    "        # Sort to ensure consistent ordering\n",
    "        chars = sorted(list(all_chars))\n",
    "\n",
    "        # 0 reserved for CTC blank\n",
    "        self.char_to_idx = {char: idx + 1 for idx, char in enumerate(chars)}\n",
    "        self.char_to_idx['BLANK'] = 0\n",
    "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
    "\n",
    "        print(f\"Total unique characters: {len(chars)}\")\n",
    "        print(f\"Characters: {repr(''.join(chars[:50]))}...\" if len(chars) > 50 else f\"Characters: {repr(''.join(chars))}\")\n",
    "\n",
    "    def encode(self, text):\n",
    "        return [self.char_to_idx.get(char, 0) for char in text]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        chars = []\n",
    "        for idx in indices:\n",
    "            if idx != 0 and idx in self.idx_to_char:\n",
    "                chars.append(self.idx_to_char[idx])\n",
    "        return ''.join(chars)\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(self.char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T23:56:54.837335Z",
     "iopub.status.busy": "2025-12-21T23:56:54.837197Z",
     "iopub.status.idle": "2025-12-21T23:56:54.851043Z",
     "shell.execute_reply": "2025-12-21T23:56:54.850640Z",
     "shell.execute_reply.started": "2025-12-21T23:56:54.837324Z"
    },
    "id": "jH_V0iziiyus",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class OCRDataset(Dataset):\n",
    "    def __init__(self, json_path, img_dir, encoder, transform=None, img_height=32, img_width=256):\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.encoder = encoder\n",
    "        self.image_paths = list(self.data.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_paths[idx]\n",
    "        img_path = self.img_dir / img_name\n",
    "        text = self.data[img_name]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception:\n",
    "            image = Image.new('RGB', (self.img_width, self.img_height), color='white')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        encoded_text = self.encoder.encode(text)\n",
    "        return image, torch.LongTensor(encoded_text), text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T23:56:54.852193Z",
     "iopub.status.busy": "2025-12-21T23:56:54.852060Z",
     "iopub.status.idle": "2025-12-21T23:56:54.866177Z",
     "shell.execute_reply": "2025-12-21T23:56:54.865750Z",
     "shell.execute_reply.started": "2025-12-21T23:56:54.852176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# CTC Decoder with Beam Search\n",
    "def ctc_decode(predictions, encoder, beam_width=5):\n",
    "    # Chuyển sang CPU nếu đang ở GPU\n",
    "    if predictions.is_cuda:\n",
    "        predictions = predictions.cpu()\n",
    "    \n",
    "    # Chuyển Logits -> Log Probabilities (để cộng log thay vì nhân xác suất)\n",
    "    predictions = torch.nn.functional.log_softmax(predictions, dim=2).detach().numpy()\n",
    "    \n",
    "    decoded_batch = []\n",
    "    \n",
    "    for probs in predictions:\n",
    "        beam = {(): (0.0, -float('inf'))}\n",
    "        \n",
    "        for t in range(len(probs)):\n",
    "            next_beam = defaultdict(lambda: (-float('inf'), -float('inf')))\n",
    "            top_k = min(beam_width, probs.shape[1])\n",
    "            top_indices = np.argsort(probs[t])[-top_k:]\n",
    "            \n",
    "            for prefix, (p_b, p_nb) in beam.items():\n",
    "                p_blank = probs[t][0]\n",
    "                n_p_b, n_p_nb = next_beam[prefix]\n",
    "                n_p_b = np.logaddexp(n_p_b, np.logaddexp(p_b, p_nb) + p_blank)\n",
    "                next_beam[prefix] = (n_p_b, n_p_nb)\n",
    "\n",
    "                for c in top_indices:\n",
    "                    if c == 0: continue # Đã xử lý ở trên\n",
    "                    p_char = probs[t][c]\n",
    "                    if len(prefix) > 0 and prefix[-1] == c:\n",
    "                        # Trường hợp lặp ký tự (ví dụ: \"aa\")\n",
    "                        # a) Nếu trước đó là non-blank (cùng ký tự) -> Merge (không thêm ký tự mới)\n",
    "                        n_p_b, n_p_nb = next_beam[prefix]\n",
    "                        n_p_nb = np.logaddexp(n_p_nb, p_nb + p_char)\n",
    "                        next_beam[prefix] = (n_p_b, n_p_nb)\n",
    "                        \n",
    "                        # b) Nếu trước đó là blank -> Extend (thêm ký tự mới)\n",
    "                        new_prefix = prefix + (c,)\n",
    "                        n_p_b, n_p_nb = next_beam[new_prefix]\n",
    "                        n_p_nb = np.logaddexp(n_p_nb, p_b + p_char)\n",
    "                        next_beam[new_prefix] = (n_p_b, n_p_nb)\n",
    "                    else:\n",
    "                        # Trường hợp ký tự mới\n",
    "                        new_prefix = prefix + (c,)\n",
    "                        n_p_b, n_p_nb = next_beam[new_prefix]\n",
    "                        # Có thể nối từ cả blank và non-blank\n",
    "                        n_p_nb = np.logaddexp(n_p_nb, np.logaddexp(p_b, p_nb) + p_char)\n",
    "                        next_beam[new_prefix] = (n_p_b, n_p_nb)\n",
    "            sorted_beam = sorted(\n",
    "                next_beam.items(),\n",
    "                key=lambda x: np.logaddexp(x[1][0], x[1][1]),\n",
    "                reverse=True\n",
    "            )\n",
    "            beam = dict(sorted_beam[:beam_width])\n",
    "        best_prefix = max(beam.items(), key=lambda x: np.logaddexp(x[1][0], x[1][1]))[0]\n",
    "        decoded_batch.append(encoder.decode(best_prefix))\n",
    "    return decoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-21T23:56:54.866862Z",
     "iopub.status.busy": "2025-12-21T23:56:54.866686Z",
     "iopub.status.idle": "2025-12-21T23:56:54.880583Z",
     "shell.execute_reply": "2025-12-21T23:56:54.880192Z",
     "shell.execute_reply.started": "2025-12-21T23:56:54.866846Z"
    },
    "id": "JDypNLs2i4O7",
    "outputId": "4ba420ee-9aee-45c2-d00c-9ad796f074a9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, encoder, epoch):\n",
    "    if not hasattr(train_epoch, \"scaler\"):\n",
    "        train_epoch.scaler = GradScaler()\n",
    "    scaler = train_epoch.scaler\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch} [Train]', ncols=100)\n",
    "\n",
    "    for images, targets, target_texts in pbar:\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "\n",
    "            input_lengths = torch.full(\n",
    "                (outputs.size(1),),\n",
    "                outputs.size(0),\n",
    "                dtype=torch.long,\n",
    "                device=device\n",
    "            )\n",
    "            target_lengths = torch.LongTensor([len(t) for t in targets]).to(device)\n",
    "            targets_flat = torch.cat(targets).to(device)\n",
    "\n",
    "            loss = criterion(\n",
    "                outputs.log_softmax(2),\n",
    "                targets_flat,\n",
    "                input_lengths,\n",
    "                target_lengths\n",
    "            )\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T23:56:54.881270Z",
     "iopub.status.busy": "2025-12-21T23:56:54.881095Z",
     "iopub.status.idle": "2025-12-21T23:56:54.893569Z",
     "shell.execute_reply": "2025-12-21T23:56:54.893178Z",
     "shell.execute_reply.started": "2025-12-21T23:56:54.881254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate(model, dataloader, criterion, device, encoder, dataset_name=\"Valid\"):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_sent = 0\n",
    "    total_edit_dist = 0.0\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=f'{dataset_name:>7}', ncols=100, leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets, target_texts in pbar:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            outputs_for_loss = outputs.permute(1, 0, 2)\n",
    "\n",
    "            # Calculate CTC loss\n",
    "            input_lengths = torch.full((outputs_for_loss.size(1),), outputs_for_loss.size(0), dtype=torch.long)\n",
    "            target_lengths = torch.LongTensor([len(t) for t in targets])\n",
    "            targets_flat = torch.cat(targets)\n",
    "            loss = criterion(outputs_for_loss.log_softmax(2), targets_flat, input_lengths, target_lengths)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Decode\n",
    "            predictions = ctc_decode(outputs, encoder)\n",
    "\n",
    "            # Evaluate\n",
    "            for pred, true in zip(predictions, target_texts):\n",
    "                pred, true = pred.strip(), true.strip()\n",
    "                total_samples += 1\n",
    "\n",
    "                if pred == true:\n",
    "                    correct_sent += 1\n",
    "\n",
    "                total_edit_dist += editdistance.eval(pred, true)\n",
    "\n",
    "            current_acc = 100 * correct_sent / total_samples if total_samples > 0 else 0\n",
    "            pbar.set_postfix({'acc': f'{current_acc:.2f}%'})\n",
    "\n",
    "    # Average metrics\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    sent_acc = 100 * correct_sent / total_samples if total_samples > 0 else 0\n",
    "    avg_lev_dist = total_edit_dist / total_samples if total_samples > 0 else 0\n",
    "\n",
    "    return avg_loss, sent_acc, avg_lev_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-21T23:59:14.397171Z",
     "iopub.status.busy": "2025-12-21T23:59:14.396659Z",
     "iopub.status.idle": "2025-12-22T01:19:47.184578Z",
     "shell.execute_reply": "2025-12-22T01:19:47.184005Z",
     "shell.execute_reply.started": "2025-12-21T23:59:14.397154Z"
    },
    "id": "kzlCufSTi5Hu",
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Total unique characters: 117\n",
      "Characters: ' !\"&\\'(),-./0123456789:;?abcdefghijklmnopqrstuvwxyz'...\n",
      "Train: 12225 | Valid: 1897\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b5_lukemelas-1a07897c.pth\" to C:\\Users\\Admin/.cache\\torch\\hub\\checkpoints\\efficientnet_b5_lukemelas-1a07897c.pth\n",
      "100%|██████████| 117M/117M [00:20<00:00, 5.97MB/s] \n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1552\\385247376.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  train_epoch.scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   0%|                                                     | 0/1529 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'train_json': 'dataset/dataset/train.json',\n",
    "    'train_img_dir': 'dataset/dataset/train/images',\n",
    "    'valid_json': 'dataset/dataset/valid.json',\n",
    "    'valid_img_dir': 'dataset/dataset/valid/images',\n",
    "    'img_height': 128,\n",
    "    'img_width': 1024,\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 60,\n",
    "    'learning_rate': 0.0002,\n",
    "    'num_workers': 8,\n",
    "    'save_dir': './output/',\n",
    "    'use_pretrained': True,\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['save_dir'], exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}\\n')\n",
    "\n",
    "with open(CONFIG['train_json'], 'r', encoding='utf-8') as f:\n",
    "    train_labels = json.load(f)\n",
    "encoder = CharacterEncoder(train_labels)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_height'], CONFIG['img_width'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_height'], CONFIG['img_width'])),\n",
    "    transforms.RandomAffine(degrees = 10, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "    transforms.RandomGrayscale(p = 0.2),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.2),\n",
    "    transforms.RandomAutocontrast(p=0.2),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_height'], CONFIG['img_width'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = OCRDataset(CONFIG['train_json'], CONFIG['train_img_dir'], encoder, train_transform)\n",
    "valid_dataset = OCRDataset(CONFIG['valid_json'], CONFIG['valid_img_dir'], encoder, val_transform)\n",
    "print(f\"Train: {len(train_dataset)} | Valid: {len(valid_dataset)}\\n\")\n",
    "\n",
    "collate_fn = lambda x: (\n",
    "    torch.stack([item[0] for item in x]),\n",
    "    [item[1] for item in x],\n",
    "    [item[2] for item in x]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True,\n",
    "                          num_workers=CONFIG['num_workers'], collate_fn=collate_fn, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['batch_size'], shuffle=False,\n",
    "                          num_workers=CONFIG['num_workers'], collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "model = CRNN(encoder.num_classes(), hidden_size=256, pretrained=CONFIG['use_pretrained']).to(device)\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "best_valid_acc = 0\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(1, CONFIG['num_epochs'] + 1):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device, encoder, epoch)\n",
    "    valid_loss, valid_acc, valid_lev = validate(model, valid_loader, criterion, device, encoder)\n",
    "    scheduler.step(valid_loss)\n",
    "    print(f\"Epoch {epoch:2d} | Train Loss: {train_loss:.4f} | Valid Acc: {valid_acc:.2f}% | Valid Loss: {valid_loss:.4f}\")\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        save_path = os.path.join(CONFIG['save_dir'], 'best_model.pth')\n",
    "        #torch.save(model.state_dict(), save_path)\n",
    "        print(f\"✅ Saved best model (Acc: {best_valid_acc:.2f}%)\")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best Validation Accuracy: {best_valid_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T01:40:38.439822Z",
     "iopub.status.busy": "2025-12-22T01:40:38.439442Z",
     "iopub.status.idle": "2025-12-22T01:53:10.654922Z",
     "shell.execute_reply": "2025-12-22T01:53:10.653962Z",
     "shell.execute_reply.started": "2025-12-22T01:40:38.439806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m      1\u001b[0m CONFIG \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_json\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/dataset/train.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_img_dir\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/dataset/train/images\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_pretrained\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m }\n\u001b[1;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m CRNN(\u001b[43mencoder\u001b[49m\u001b[38;5;241m.\u001b[39mnum_classes(), hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_pretrained\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Load the best model and generate predictions\u001b[39;00m\n\u001b[0;32m     18\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'train_json': 'dataset/dataset/train.json',\n",
    "    'train_img_dir': 'dataset/dataset/train/images',\n",
    "    'valid_json': 'dataset/dataset/valid.json',\n",
    "    'valid_img_dir': 'dataset/dataset/valid/images',\n",
    "    'img_height': 128,\n",
    "    'img_width': 1024,\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 60,\n",
    "    'learning_rate': 0.00001,\n",
    "    'num_workers': 8,\n",
    "    'save_dir': './output/',\n",
    "    'use_pretrained': True,\n",
    "}\n",
    "\n",
    "model = CRNN(encoder.num_classes(), hidden_size=256, pretrained=CONFIG['use_pretrained']).to(device)\n",
    "# Load the best model and generate predictions\n",
    "best_model_path = os.path.join(CONFIG['save_dir'], 'best_model.pth')\n",
    "if os.path.exists(best_model_path):\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    print(f\"\\nLoaded best model from: {best_model_path}\")\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "best_valid_acc = 0\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(1, CONFIG['num_epochs'] + 1):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device, encoder, epoch)\n",
    "    valid_loss, valid_acc, valid_lev = validate(model, valid_loader, criterion, device, encoder)\n",
    "    scheduler.step(valid_loss)\n",
    "    print(f\"Epoch {epoch:2d} | Train Loss: {train_loss:.4f} | Valid Acc: {valid_acc:.2f}% | Valid Loss: {valid_loss:.4f}\")\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        save_path = os.path.join(CONFIG['save_dir'], 'best_model.pth')\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"✅ Saved best model (Acc: {best_valid_acc:.2f}%)\")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best Validation Accuracy: {best_valid_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-12-21T23:58:44.329031Z",
     "iopub.status.idle": "2025-12-21T23:58:44.329169Z",
     "shell.execute_reply": "2025-12-21T23:58:44.329108Z",
     "shell.execute_reply.started": "2025-12-21T23:58:44.329101Z"
    },
    "id": "TA8dB2_zjAah",
    "outputId": "91c64be4-743d-4e8c-ce66-5b420f3f7f53",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_and_save(model, encoder, img_dir, output_json, device, img_height=32, img_width=1024):\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "\n",
    "    # Define the same image transformation used during training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    img_names = sorted(os.listdir(img_dir))\n",
    "    print(f\"Predicting {len(img_names)} images from: {img_dir}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_name in tqdm(img_names):\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "\n",
    "            # Load and preprocess image\n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            image = transform(image).unsqueeze(0).to(device)  # shape: (1, 3, H, W)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(image)  # shape: (1, W, num_classes)\n",
    "\n",
    "            # Decode using CTC greedy decoding\n",
    "            pred_text = ctc_decode(output, encoder)[0]\n",
    "\n",
    "            # Store prediction\n",
    "            predictions[img_name] = pred_text.strip()\n",
    "\n",
    "    # Save results to JSON file\n",
    "    os.makedirs(os.path.dirname(output_json), exist_ok=True)\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Saved predictions to: {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2025-12-21T23:58:44.329542Z",
     "iopub.status.idle": "2025-12-21T23:58:44.329664Z",
     "shell.execute_reply": "2025-12-21T23:58:44.329608Z",
     "shell.execute_reply.started": "2025-12-21T23:58:44.329602Z"
    },
    "id": "K_xWZpu0jBYN",
    "outputId": "d8c98876-7f53-4c6c-a06f-50d70f0d4e9e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "    # Load the best model and generate predictions\n",
    "    best_model_path = os.path.join(CONFIG['save_dir'], 'best_model.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        print(f\"\\nLoaded best model from: {best_model_path}\")\n",
    "\n",
    "        # Predict on public test set\n",
    "        predict_and_save(\n",
    "            model, encoder,\n",
    "            img_dir='dataset/public_test/images',\n",
    "            output_json='./public_test.json',\n",
    "            device=device,\n",
    "            img_height=CONFIG['img_height'],\n",
    "            img_width=CONFIG['img_width']\n",
    "        )\n",
    "\n",
    "        # Predict on private test set\n",
    "        predict_and_save(\n",
    "            model, encoder,\n",
    "            img_dir='dataset/private_test/images',\n",
    "            output_json='./private_test.json',\n",
    "            device=device,\n",
    "            img_height=CONFIG['img_height'],\n",
    "            img_width=CONFIG['img_width']\n",
    "        )\n",
    "    else:\n",
    "        print(\"Best model not found. Skipping prediction.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaH100",
   "dataSources": [
    {
     "databundleVersionId": 14559231,
     "sourceId": 118448,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
